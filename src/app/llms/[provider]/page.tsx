import type { Metadata } from "next";
import * as React from "react";
import {
  HydrationBoundary,
  QueryClient,
  dehydrate,
} from "@tanstack/react-query";
import { modelsDataOptions } from "@/features/data-explorer/models/models-query-options";
import { ProviderLlmClient } from "./provider-llm-client";
import { modelsSearchParamsCache } from "@/features/data-explorer/models/models-search-params";
import { getModelsPage } from "@/lib/models-loader";
import { buildModelsSchema } from "@/features/data-explorer/models/build-models-schema";
import { logger } from "@/lib/logger";

export const revalidate = 43200;

const SHARED_OG_IMAGE = "/assets/data-table-infinite.png";

type Props = { params: Promise<{ provider: string }> };

export async function generateMetadata({ params }: Props): Promise<Metadata> {
  const { provider } = await params;
  const name = decodeURIComponent(provider);
  const title = `${name} LLM Pricing | Deploybase`;
  const description = `Real-time ${name} LLM inference pricing. Compare models, token costs, and availability.`;

  return {
    title,
    description,
    alternates: { canonical: `/llms/${encodeURIComponent(provider)}` },
    openGraph: {
      title,
      description,
      images: [SHARED_OG_IMAGE],
      url: `/llms/${encodeURIComponent(provider)}`,
      type: "website",
    },
    twitter: {
      card: "summary_large_image",
      title,
      description,
      images: [SHARED_OG_IMAGE],
    },
  };
}

/**
 * SEO landing page for a specific LLM provider.
 *
 * We intentionally do NOT accept the `searchParams` page prop here because
 * doing so would opt this route into fully dynamic rendering (per Next.js docs)
 * and break our ISR strategy (revalidate = 43200s / 12hrs).
 *
 * Instead we seed the nuqs searchParamsCache directly with the route-segment
 * provider. This gives us:
 *   - Server: filtered HTML + JSON-LD for crawlers (ISR-cached)
 *   - Client: ProviderLlmClient wrapper pushes ?provider=X into the URL via
 *     useLayoutEffect so nuqs and React Query pick up the filter after hydration
 *
 * This matches the same pattern used by the main /llms page which also calls
 * modelsSearchParamsCache.parse({}) without accepting searchParams.
 */
export default async function LlmProviderPage({ params }: Props) {
  const { provider } = await params;
  const decodedProvider = decodeURIComponent(provider);
  const parsedSearch = modelsSearchParamsCache.parse({ provider: [decodedProvider] });
  const queryClient = new QueryClient();
  const captured: { firstPage: Awaited<ReturnType<typeof getModelsPage>> | null } = { firstPage: null };

  try {
    const infiniteOptions = modelsDataOptions(parsedSearch);
    await queryClient.prefetchInfiniteQuery({
      ...infiniteOptions,
      queryFn: async ({ pageParam }) => {
        const cursor =
          typeof pageParam?.cursor === "number" ? pageParam.cursor : null;
        const size =
          (pageParam as { size?: number } | undefined)?.size ??
          parsedSearch.size ??
          50;
        const result = await getModelsPage({
          ...parsedSearch,
          cursor,
          size,
          uuid: null,
        });
        if (!captured.firstPage && (cursor === null || cursor === 0)) {
          captured.firstPage = result;
        }
        return result;
      },
    });
  } catch (error) {
    logger.error("[LlmProviderPage] Failed to prefetch models data", {
      provider: decodedProvider,
      error: error instanceof Error ? error.message : String(error),
    });
  }

  const dehydratedState = dehydrate(queryClient);
  const schemaMarkup = buildModelsSchema(captured.firstPage, `${decodedProvider} LLM Inference Pricing Feed`);

  return (
    <HydrationBoundary state={dehydratedState}>
      {schemaMarkup ? (
        <script
          type="application/ld+json"
          suppressHydrationWarning
          dangerouslySetInnerHTML={{
            __html: JSON.stringify(schemaMarkup).replace(/</g, "\\u003c"),
          }}
        />
      ) : null}
      <h1 className="sr-only">{decodedProvider} LLM Pricing</h1>
      <div
        className="flex min-h-dvh w-full flex-col sm:flex-row pt-2 sm:p-0"
        style={{
          "--total-padding-mobile": "calc(0.5rem + 0.5rem)",
          "--total-padding-desktop": "3rem",
        } as React.CSSProperties}
      >
        <ProviderLlmClient provider={decodedProvider} />
      </div>
    </HydrationBoundary>
  );
}
